{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b1d9b00",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Ola Mundo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fe9d517",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/04/04 23:19:27 WARN Utils: Your hostname, codespaces-1f695e resolves to a loopback address: 127.0.0.1; using 10.0.5.187 instead (on interface eth0)\n",
      "25/04/04 23:19:27 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/04/04 23:19:28 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame de Vendas:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------+-----------+\n",
      "|id_cliente|valor_compra|data_compra|\n",
      "+----------+------------+-----------+\n",
      "|         1|       150.5| 2024-01-15|\n",
      "|         2|      200.75| 2024-02-20|\n",
      "|         3|        99.9| 2024-03-10|\n",
      "|         1|       300.0| 2023-11-25|\n",
      "|         4|       250.5| 2023-12-05|\n",
      "|         3|       120.0| 2024-02-12|\n",
      "|         5|       180.0| 2024-04-10|\n",
      "|         2|       220.0| 2024-01-25|\n",
      "|         6|       500.0| 2023-09-18|\n",
      "|         5|       350.0| 2023-10-10|\n",
      "+----------+------------+-----------+\n",
      "\n",
      "Clientes com maior valor de compra:\n",
      "+----------+------------+-----------+\n",
      "|id_cliente|valor_compra|data_compra|\n",
      "+----------+------------+-----------+\n",
      "|         6|       500.0| 2023-09-18|\n",
      "|         5|       350.0| 2023-10-10|\n",
      "|         1|       300.0| 2023-11-25|\n",
      "|         4|       250.5| 2023-12-05|\n",
      "|         2|       220.0| 2024-01-25|\n",
      "|         2|      200.75| 2024-02-20|\n",
      "|         5|       180.0| 2024-04-10|\n",
      "|         1|       150.5| 2024-01-15|\n",
      "|         3|       120.0| 2024-02-12|\n",
      "|         3|        99.9| 2024-03-10|\n",
      "+----------+------------+-----------+\n",
      "\n",
      "Total de vendas anuais:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------+\n",
      "|ano_compra|total_vendas|\n",
      "+----------+------------+\n",
      "|      2023|      1400.5|\n",
      "|      2024|      971.15|\n",
      "+----------+------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/04/04 23:19:40 WARN GarbageCollectionMetrics: To enable non-built-in garbage collector(s) List(G1 Concurrent GC), users should configure it(them) to spark.eventLog.gcMetrics.youngGenerationGarbageCollectors or spark.eventLog.gcMetrics.oldGenerationGarbageCollectors\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, year, sum\n",
    "\n",
    "# Criar uma SparkSession\n",
    "spark = SparkSession.builder.appName(\"DesafioFinalVendas\").getOrCreate()\n",
    "\n",
    "# Dados fictícios de vendas: id_cliente, valor_compra, data_compra\n",
    "dados_vendas = [\n",
    "    (1, 150.50, \"2024-01-15\"),\n",
    "    (2, 200.75, \"2024-02-20\"),\n",
    "    (3, 99.90, \"2024-03-10\"),\n",
    "    (1, 300.00, \"2023-11-25\"),\n",
    "    (4, 250.50, \"2023-12-05\"),\n",
    "    (3, 120.00, \"2024-02-12\"),\n",
    "    (5, 180.00, \"2024-04-10\"),\n",
    "    (2, 220.00, \"2024-01-25\"),\n",
    "    (6, 500.00, \"2023-09-18\"),\n",
    "    (5, 350.00, \"2023-10-10\")\n",
    "]\n",
    "\n",
    "# Definir os nomes das colunas\n",
    "colunas = [\"id_cliente\", \"valor_compra\", \"data_compra\"]\n",
    "\n",
    "# Criar um DataFrame a partir dos dados fictícios\n",
    "df_vendas = spark.createDataFrame(dados_vendas, colunas)\n",
    "\n",
    "# Mostrar o DataFrame\n",
    "print(\"DataFrame de Vendas:\")\n",
    "df_vendas.show()\n",
    "\n",
    "# 1. Identificar os clientes com maior valor de compra\n",
    "# Ordenar pelo valor da compra de forma decrescente e pegar os 10 primeiros clientes\n",
    "clientes_maior_valor = df_vendas.orderBy(col(\"valor_compra\").desc()).limit(10)\n",
    "\n",
    "print(\"Clientes com maior valor de compra:\")\n",
    "clientes_maior_valor.show()\n",
    "\n",
    "# 2. Agrupar as compras por ano e calcular o total de vendas anuais\n",
    "# Primeiramente, vamos extrair o ano da coluna \"data_compra\" e criar uma nova coluna \"ano_compra\"\n",
    "df_vendas = df_vendas.withColumn(\"ano_compra\", year(col(\"data_compra\")))\n",
    "\n",
    "# Agrupar por ano e somar o valor das compras\n",
    "vendas_anuais = df_vendas.groupBy(\"ano_compra\").agg(sum(\"valor_compra\").alias(\"total_vendas\"))\n",
    "\n",
    "print(\"Total de vendas anuais:\")\n",
    "vendas_anuais.show()\n",
    "\n",
    "# 3. Salvar os resultados em um formato de sua escolha (CSV, JSON, etc.)\n",
    "# Salvando os resultados em um arquivo CSV\n",
    "vendas_anuais.write.csv(\"vendas_anuais.csv\", header=True)\n",
    "\n",
    "# Ou, caso queira salvar como JSON:\n",
    "# vendas_anuais.write.json(\"vendas_anuais.json\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
